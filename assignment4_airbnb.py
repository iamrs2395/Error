# -*- coding: utf-8 -*-
"""Assignment4_AIRBNB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xk5Zi-qdIdT1IktAg0X1YXi3wpejMUCX
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import seaborn as sns

df=pd.read_csv("/content/drive/MyDrive/Deep Learning/AB_NYC_2019.csv")
df.head()

df.shape

df.info()

df.isnull().sum()

df.drop(['id','host_id','host_name'],axis=1,inplace=True)

df.head()

df.isnull().sum()

((df.isnull().sum())/df.shape[0]*100)

df.drop(['last_review'],axis=1,inplace=True)

((df.isnull().sum())/df.shape[0]*100)

df.info()

df["reviews_per_month"].replace(np.nan,df["reviews_per_month"].mean(),inplace=True)

df.isnull().sum()

dt=list(df[((df.isnull().sum(axis=1)/df.shape[1])*100)>5].index)

for x in dt:
    df=df.drop(x)

df.isnull().sum()

#is_NaN = df.isnull()
#row_has_NaN = is_NaN.any(axis=1)
#rows_with_NaN = df[row_has_NaN]
#print(rows_with_NaN)
# checking which row is null

#df.drop([2854,3703,5775,5975,6269,6567,6605,8841,11963,12824,13059,13401,15819,16071,18047,28889],axis=0,inplace=True)#dropping the row

#df.isnull().sum()

df.info()

df_num=df.select_dtypes(["int64","float64"])
df_cat=df.select_dtypes("object")

from sklearn.preprocessing import LabelEncoder
for col in df_cat: 
    le=LabelEncoder()
    df_cat[col]=le.fit_transform(df_cat[col])

df_cat.head()

df_new=pd.concat([df_num,df_cat],axis=1)
df_new.head()

X=df_new.drop("price",axis=1) #Input means independent variable
Y=df_new["price"]

from sklearn.model_selection import train_test_split
from keras.layers import Dropout
from keras import regularizers
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1)

from sklearn.preprocessing import StandardScaler
ss=StandardScaler()
X_train=ss.fit_transform(X_train)
X_test=ss.transform(X_test)

#model = tf.keras.Sequential([
#tf.keras.layers.Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X.shape[1],)),
#    Dropout(0.3),  #30% neuron deactivate
#  tf.keras.layers.Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
#    Dropout(0.3),
#    tf.keras.layers.Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
#    Dropout(0.3),
#    tf.keras.layers.Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
#    Dropout(0.3),
#    tf.keras.layers.Dense(1,kernel_regularizer=regularizers.l2(0.01))
#])

#model = tf.keras.Sequential([
#tf.keras.layers.Dense(10, activation='relu', input_shape=(X.shape[1],)),
#    tf.keras.layers.Dense(128, activation='relu', ),
#    tf.keras.layers.Dense(64, activation='relu', ),
#    Dropout(0.3),
#    tf.keras.layers.Dense(32, activation='relu', ),
#    tf.keras.layers.Dense(1)
#])

model=tf.keras.Sequential([
                           tf.keras.layers.Dense(128,activation='relu',input_shape=(X.shape[1],)),
                           tf.keras.layers.Dense(256,activation='relu'),
                           tf.keras.layers.Dense(256,activation='relu'),
                           tf.keras.layers.Dense(1,activation='linear')
])

opt=tf.keras.optimizers.Adam(learning_rate=0.5)
#rmse=tf.keras.metrics.RootMeanSquaredError()
model.compile(optimizer=opt,
              loss='mean_squared_error',
              metrics=['accuracy'])

trained_model=model.fit(X_train,Y_train,epochs=100,batch_size=32)
trained_model

Y_pred=model.predict(X_test)
Y_pred
from sklearn.metrics import r2_score
print(r2_score(Y_test,Y_pred))

